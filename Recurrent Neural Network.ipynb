{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X0=tf.placeholder(tf.float32,[None, n_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1=tf.placeholder(tf.float32,[None, n_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Wx = tf.Variable(tf.random_normal(shape=[n_inputs, n_neurons], dtype=tf.float32))\n",
    "Wy = tf.Variable(tf.random_normal(shape=[n_inputs, n_neurons], dtype=tf.float32))\n",
    "b= tf.Variable(tf.zeros([1,n_neurons], dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y0 = tf.tanh(tf.matmul(X0, Wx) +b)\n",
    "Y1 = tf.tanh(tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) +b)\n",
    "#tanh is the activation function. in dynamic rnn, by default in tf.contrib.rnn.BasicRNNCell, it is tanh.\n",
    "#however, you can change it to any other activation function using the argument \"activation\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X0_batch =  np.array([[0,1,2],[3,4,5],[6,7,8],[9,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X = pd.DataFrame(X0_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1_batch =  np.array([[9,8,7],[0,0,0],[6,5,4],[3,2,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0: X0_batch, X1: X1_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Y0_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Unrolling Through Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell,[X0,X1], dtype=tf.float32)\n",
    "Y0, Y1=output_seqs\n",
    "#function returns two objects. first is a python list containing the output tensors for each time step. \n",
    "#The second is a tensor containing the final states of the network. When you are using basic cells, the final state is simply\n",
    "#equal to last output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X0_batch =  np.array([[0,1,2],[3,4,5],[6,7,8],[9,0,1]])\n",
    "X1_batch =  np.array([[9,8,7],[0,0,0],[6,5,4],[3,2,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    Y0_val, Y1_val = sess.run([Y0,Y1],feed_dict={X0: X0_batch, X1:X1_batch })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Y0_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there were 50 time steps, it would not be very convenient to have to define 50 input placeholders and 50 output tensors. We can simplify this.\n",
    "\n",
    "it takes a single input placeholder of shape  [None, n_steps, n_inputs] where the first dimension isthe mini-batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "X=tf.placeholder(tf.float32, [None, n_steps, n_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_seqs = tf.unstack(tf.transpose(X, perm=[1,0,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell,X_seqs, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = tf.transpose(tf.stack(output_seqs), perm=[1,0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_batch = np.array([ \n",
    "    [[0,1,2],[9,8,7]],#instance 0\n",
    "    [[3,4,5],[0,0,0]],#instance 1\n",
    "    [[6,7,8],[6,5,4]],#instance 2\n",
    "    [[9,0,1],[3,2,1]]])#instance 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val, states_val = sess.run([outputs, states], feed_dict={X:X_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(states_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Unrolling Through Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "X=tf.placeholder(tf.float32, [None, n_steps, n_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_batch = np.array([ \n",
    "    [[0,1,2],[9,8,7]],#instance 0\n",
    "    [[3,4,5],[0,0,0]],#instance 1\n",
    "    [[6,7,8],[6,5,4]],#instance 2\n",
    "    [[9,0,1],[3,2,1]]])#instance 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val, states_val = sess.run([outputs, states], feed_dict={X:X_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(outputs_val)\n",
    "print(outputs_val.shape)\n",
    "\n",
    "print(states_val)\n",
    "print(states_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASIC LSTM EXAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "X_batch = np.array([ \n",
    "    [[0,1,2],[9,8,7]],#instance 0\n",
    "    [[3,4,5],[0,0,0]],#instance 1\n",
    "    [[6,7,8],[6,5,4]],#instance 2\n",
    "    [[9,0,1],[3,2,1]]])#instance 3\n",
    "\n",
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X=tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "\n",
    "# create 2 LSTMCells\n",
    "rnn_layers = [tf.nn.rnn_cell.LSTMCell(size) for size in [128, 256]]\n",
    "#First cell has number of units as 128 and the second cell has 256\n",
    "\n",
    "# create a RNN cell composed sequentially of a number of RNNCells\n",
    "multi_rnn_cell = tf.nn.rnn_cell.MultiRNNCell(rnn_layers)\n",
    "\n",
    "# 'outputs' is a tensor of shape [batch_size, max_time, 256]\n",
    "# 'state' is a N-tuple where N is the number of LSTMCells containing a\n",
    "# tf.contrib.rnn.LSTMStateTuple for each cell\n",
    "outputs, states = tf.nn.dynamic_rnn(cell=multi_rnn_cell,\n",
    "                                   inputs=X,\n",
    "                                   dtype=tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    outputs_val, states_val = sess.run([outputs, states], feed_dict={X:X_batch})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.00769336 -0.00032055 -0.0019508  ...  0.00164839 -0.00298414\n",
      "   -0.00504108]\n",
      "  [ 0.06101465 -0.00499493 -0.00471805 ...  0.01425603 -0.02972551\n",
      "   -0.02672425]]\n",
      "\n",
      " [[ 0.03041571 -0.00122588 -0.00342316 ...  0.00724636 -0.01426015\n",
      "   -0.01749035]\n",
      "  [ 0.04229382 -0.00407521 -0.01046767 ...  0.01387198 -0.02256514\n",
      "   -0.02741067]]\n",
      "\n",
      " [[ 0.04720089 -0.00186801 -0.00530894 ...  0.00951193 -0.02356498\n",
      "   -0.02267964]\n",
      "  [ 0.09486194 -0.00958257 -0.01041569 ...  0.02924553 -0.05174449\n",
      "   -0.05033881]]\n",
      "\n",
      " [[ 0.02736288 -0.00850442 -0.0024518  ...  0.00669371 -0.00675236\n",
      "   -0.01343909]\n",
      "  [ 0.05584113 -0.01584079 -0.00768016 ...  0.01812207 -0.01703749\n",
      "   -0.03205018]]]\n",
      "(4, 2, 256)\n",
      "(LSTMStateTuple(c=array([[ 6.41405284e-01,  2.58917689e-01, -6.24168925e-02,\n",
      "         3.81408930e-01,  1.17082417e-01, -8.20610523e-02,\n",
      "        -3.69117349e-01,  6.84079349e-01, -5.06348014e-01,\n",
      "        -7.35761762e-01, -4.80452292e-02,  4.45271544e-02,\n",
      "        -2.52230503e-02, -1.03973255e-01, -1.68273553e-01,\n",
      "        -1.92367330e-01, -6.69244826e-02, -1.51962221e-01,\n",
      "        -5.07086277e-01, -1.54078841e-01, -6.70361459e-01,\n",
      "         3.30755204e-01,  4.67723876e-01,  4.53920253e-02,\n",
      "        -1.10517554e-02, -1.85079888e-01,  1.63495794e-01,\n",
      "         1.83371767e-01, -3.69212836e-01,  3.41493189e-01,\n",
      "         2.22267672e-01, -3.34129389e-03,  2.46746570e-01,\n",
      "        -3.16875041e-01,  3.18529606e-01,  4.30844069e-01,\n",
      "        -9.33172032e-02, -2.76609927e-01, -3.33467484e-01,\n",
      "        -3.61175060e-01,  5.20842522e-02,  6.50904775e-01,\n",
      "        -4.52884734e-01,  7.73702040e-02,  3.08707714e-01,\n",
      "         1.05866551e-01, -5.85704267e-01, -1.39473928e-02,\n",
      "         9.09264311e-02, -4.97150540e-01,  2.45686263e-01,\n",
      "        -4.48079318e-01,  3.97108570e-02, -2.00709879e-01,\n",
      "         2.78094679e-01,  2.91026011e-03,  5.88269532e-01,\n",
      "         3.22741747e-01,  2.17557281e-01,  1.61828190e-01,\n",
      "        -1.89268827e-01,  2.41785303e-01, -4.77247119e-01,\n",
      "         1.98893711e-01, -2.22163230e-01, -3.18842679e-01,\n",
      "        -1.78224266e-01,  1.93556622e-01,  4.46026295e-01,\n",
      "        -5.42568207e-01,  4.67155129e-01,  4.04831976e-01,\n",
      "         5.92443123e-02, -4.18311477e-01,  5.71470633e-02,\n",
      "         2.26716757e-01, -3.64351571e-01, -1.34213120e-01,\n",
      "         4.47984859e-02,  1.83403701e-01,  6.38620853e-01,\n",
      "        -4.33488280e-01, -2.21169442e-01,  4.60583001e-01,\n",
      "        -6.02316856e-01, -1.46989554e-01, -4.68730658e-01,\n",
      "        -2.32016519e-01, -7.29918405e-02,  1.95104986e-01,\n",
      "        -1.16998047e-01,  1.12489358e-01, -5.28169036e-01,\n",
      "        -6.79174423e-01,  1.66587636e-01, -5.33834815e-01,\n",
      "         1.09671570e-01, -4.65133339e-01,  2.74302006e-01,\n",
      "         6.01147860e-03, -6.04787409e-01,  1.92883462e-01,\n",
      "         1.63185567e-01,  4.24255282e-01, -3.87060523e-01,\n",
      "         1.27347559e-01, -4.72832084e-01,  4.49723542e-01,\n",
      "        -7.69249797e-02, -6.59676567e-02, -7.56485686e-02,\n",
      "         9.90313143e-02,  2.76550919e-01, -1.44424826e-01,\n",
      "        -4.05222863e-01,  3.03350300e-01,  6.20297730e-01,\n",
      "         1.39225170e-01,  1.43511653e-01, -2.03459263e-01,\n",
      "        -8.11220169e-01,  3.33915055e-01,  5.84607840e-01,\n",
      "         1.16515309e-01, -1.45729885e-01,  3.76387656e-01,\n",
      "         2.40278274e-01, -9.11581367e-02],\n",
      "       [ 2.62536079e-01,  1.03514373e-01, -4.64883819e-02,\n",
      "         1.61556259e-01,  7.76876733e-02,  2.93336809e-04,\n",
      "        -2.27031782e-01,  1.74883053e-01, -1.31070971e-01,\n",
      "        -3.18834543e-01, -4.60613072e-02,  2.78460924e-02,\n",
      "         3.15131247e-02, -5.36111780e-02, -5.07311374e-02,\n",
      "        -1.05187036e-01,  5.26035391e-03, -4.45781425e-02,\n",
      "        -1.95062146e-01, -1.08853161e-01, -2.25731134e-01,\n",
      "         1.31902456e-01,  1.31365433e-01,  3.58015187e-02,\n",
      "         5.59744937e-03, -5.61730340e-02,  1.19828805e-01,\n",
      "         4.47117686e-02, -1.54968709e-01,  8.69559050e-02,\n",
      "         3.29452902e-02,  2.22970322e-02,  3.83114666e-02,\n",
      "        -1.29260436e-01,  1.56423107e-01,  1.32116735e-01,\n",
      "        -3.86611745e-02, -4.03815247e-02, -2.38103941e-02,\n",
      "        -8.72659907e-02, -4.54829633e-02,  2.39225626e-01,\n",
      "        -2.59014308e-01,  4.54666689e-02,  2.12839156e-01,\n",
      "         4.62654717e-02, -2.30086058e-01, -3.01303156e-02,\n",
      "         5.72862774e-02, -2.08272681e-01,  1.69330806e-01,\n",
      "        -1.21632241e-01,  8.87769740e-03, -5.08639626e-02,\n",
      "         9.93454084e-02,  1.13930376e-02,  2.98665941e-01,\n",
      "         1.93419591e-01,  1.12816006e-01, -3.96201685e-02,\n",
      "        -2.88688838e-02,  1.79102346e-02, -1.92185625e-01,\n",
      "         9.67919230e-02, -9.92202386e-03, -1.04897514e-01,\n",
      "        -6.83996454e-02,  2.50666756e-02,  1.73195451e-01,\n",
      "        -1.61087796e-01,  1.47839427e-01,  2.19503015e-01,\n",
      "        -4.28524502e-02, -1.34977296e-01,  5.54794371e-02,\n",
      "         9.14940760e-02, -1.50575384e-01, -8.66776481e-02,\n",
      "        -1.61610413e-02,  6.14543930e-02,  1.98780134e-01,\n",
      "        -1.61995292e-01, -1.37018226e-02,  1.22651234e-01,\n",
      "        -2.27886885e-01, -5.44596016e-02, -1.49416044e-01,\n",
      "        -7.31704310e-02, -5.24000898e-02,  6.04012758e-02,\n",
      "         4.32321653e-02,  8.02571774e-02, -2.12517962e-01,\n",
      "        -3.01648289e-01,  2.36232821e-02, -1.63459033e-01,\n",
      "         1.09273002e-01, -2.19142213e-01,  9.53297243e-02,\n",
      "        -4.28926870e-02, -2.65648395e-01,  1.55873120e-01,\n",
      "         3.57037038e-03,  1.09300978e-01, -4.31395732e-02,\n",
      "         1.32566700e-02, -1.83564022e-01,  1.28973559e-01,\n",
      "        -1.04361787e-01, -1.19044594e-02, -7.54873455e-02,\n",
      "         4.60266173e-02,  8.62013474e-02, -1.21799923e-01,\n",
      "        -8.85059536e-02,  4.71223295e-02,  2.68584579e-01,\n",
      "         1.51340738e-02,  4.23199311e-02, -1.23802498e-01,\n",
      "        -3.08938473e-01,  1.96791530e-01,  2.02740595e-01,\n",
      "         8.35159235e-03, -5.49173057e-02,  1.78594336e-01,\n",
      "         4.60456759e-02, -5.27222455e-02],\n",
      "       [ 8.84449959e-01,  3.63680661e-01, -1.09517053e-01,\n",
      "         5.44536948e-01,  1.60753518e-01, -6.21604882e-02,\n",
      "        -5.51281869e-01,  7.53584981e-01, -5.68102002e-01,\n",
      "        -9.70781446e-01, -8.60877112e-02,  4.56104614e-02,\n",
      "        -2.71725692e-02, -1.35702908e-01, -1.97817653e-01,\n",
      "        -2.14601472e-01, -8.67550448e-02, -2.15670049e-01,\n",
      "        -5.48319280e-01, -2.25390241e-01, -8.58161569e-01,\n",
      "         4.68120456e-01,  5.74882507e-01,  1.86510272e-02,\n",
      "        -1.13021433e-02, -2.43687421e-01,  2.36143678e-01,\n",
      "         2.40005285e-01, -3.61338317e-01,  3.87206435e-01,\n",
      "         1.08461872e-01, -5.50467893e-03,  2.47881651e-01,\n",
      "        -4.12038028e-01,  5.01201630e-01,  5.12622833e-01,\n",
      "        -9.55062807e-02, -3.33483070e-01, -3.72911274e-01,\n",
      "        -4.31269079e-01,  2.37363093e-02,  7.92836070e-01,\n",
      "        -6.45464420e-01,  1.05335496e-01,  3.65748286e-01,\n",
      "         9.04957056e-02, -7.39234209e-01, -2.48390511e-02,\n",
      "         1.19893149e-01, -6.48841381e-01,  3.52343649e-01,\n",
      "        -5.11683404e-01,  5.27191274e-02, -2.65577376e-01,\n",
      "         3.57341498e-01, -1.39688728e-02,  7.46069491e-01,\n",
      "         4.00794029e-01,  2.48485222e-01,  1.23611458e-01,\n",
      "        -1.92359298e-01,  2.48924673e-01, -5.79845130e-01,\n",
      "         2.78787494e-01, -2.70368367e-01, -3.92556310e-01,\n",
      "        -2.46675625e-01,  2.29568079e-01,  6.05105162e-01,\n",
      "        -6.32961988e-01,  5.53023338e-01,  5.63615441e-01,\n",
      "         7.10800216e-02, -4.54986811e-01,  4.19010632e-02,\n",
      "         2.39642441e-01, -5.04341006e-01, -1.45505980e-01,\n",
      "         5.62311262e-02,  2.01380357e-01,  7.20332623e-01,\n",
      "        -5.11605382e-01, -2.48297065e-01,  4.18816775e-01,\n",
      "        -7.20669746e-01, -8.44057053e-02, -5.76830924e-01,\n",
      "        -2.10686788e-01, -1.14367217e-01,  2.34849259e-01,\n",
      "        -8.05443451e-02,  2.25039139e-01, -6.74770534e-01,\n",
      "        -7.78360367e-01,  1.78939909e-01, -5.86710095e-01,\n",
      "         1.41572416e-01, -5.15418828e-01,  3.65335703e-01,\n",
      "         3.10606509e-02, -7.44458199e-01,  3.23650450e-01,\n",
      "         6.45004660e-02,  5.36087215e-01, -4.35259610e-01,\n",
      "         1.32551759e-01, -6.33493900e-01,  4.66287255e-01,\n",
      "        -6.56131580e-02, -6.17746785e-02, -1.63801655e-01,\n",
      "         1.56862184e-01,  3.18813831e-01, -1.97021022e-01,\n",
      "        -4.73702908e-01,  3.12085330e-01,  8.35708618e-01,\n",
      "         1.32483676e-01,  1.86654419e-01, -3.32426786e-01,\n",
      "        -9.15070951e-01,  4.11737889e-01,  6.63827479e-01,\n",
      "         1.96020097e-01, -1.89171463e-01,  4.34510350e-01,\n",
      "         2.40076602e-01, -5.70684373e-02],\n",
      "       [ 3.86789799e-01,  1.65290043e-01, -1.94358483e-01,\n",
      "         3.12531441e-01, -8.91589466e-03,  5.03628403e-02,\n",
      "        -4.20517445e-01,  4.57975626e-01, -3.84914935e-01,\n",
      "        -3.88181627e-01, -5.71297519e-02,  8.17598477e-02,\n",
      "        -1.33723795e-01, -2.13032782e-01, -5.73121458e-02,\n",
      "         1.59513682e-01, -6.57642782e-02, -1.15405291e-01,\n",
      "        -2.54014134e-01, -1.52455941e-01, -5.44837058e-01,\n",
      "         2.98258007e-01,  3.93142879e-01, -1.25678077e-01,\n",
      "        -1.20453119e-01, -3.00399423e-01,  6.69781566e-02,\n",
      "         2.70133942e-01,  1.07827015e-01,  2.19599605e-01,\n",
      "        -1.48103654e-01, -9.03492719e-02,  3.52917671e-01,\n",
      "        -2.19689235e-01,  3.67789865e-01,  3.93186331e-01,\n",
      "        -3.42305005e-02, -3.53531301e-01, -3.35215271e-01,\n",
      "        -3.87408197e-01,  3.22566703e-02,  3.20342422e-01,\n",
      "        -3.45970660e-01,  4.21243981e-02, -7.11680353e-02,\n",
      "        -1.44875318e-01, -3.57828200e-01,  4.63810787e-02,\n",
      "         2.71715336e-02, -3.69279385e-01,  1.90210834e-01,\n",
      "        -4.69121099e-01, -2.80118249e-02, -2.20766038e-01,\n",
      "         3.59468520e-01, -2.27803633e-01,  2.46809632e-01,\n",
      "         1.60869032e-01, -8.88772383e-02,  1.94433600e-01,\n",
      "        -1.69038534e-01,  3.10283661e-01, -3.36123824e-01,\n",
      "         1.93434209e-01, -3.71629894e-01, -3.02716911e-01,\n",
      "        -2.09212095e-01,  3.96930784e-01,  3.11004698e-01,\n",
      "        -2.98830092e-01,  3.73694122e-01,  4.13867950e-01,\n",
      "         2.80649245e-01, -3.34981203e-01, -1.15344092e-01,\n",
      "        -1.92838758e-01, -3.34132642e-01,  1.78970665e-01,\n",
      "         1.59410000e-01,  2.25227714e-01,  3.63620698e-01,\n",
      "        -5.18029183e-02, -1.66821882e-01,  5.04467338e-02,\n",
      "        -3.92989695e-01,  1.02188051e-01, -2.34166205e-01,\n",
      "        -3.83529514e-02, -1.31765574e-01,  3.50105315e-01,\n",
      "        -1.87624365e-01, -9.89742279e-02, -5.07610917e-01,\n",
      "         1.17638737e-01,  2.49621227e-01, -4.35641050e-01,\n",
      "        -1.31459594e-01,  1.57858640e-01,  3.42176497e-01,\n",
      "         2.66630769e-01, -2.32990801e-01,  2.39001930e-01,\n",
      "        -1.99712947e-01,  5.12191534e-01, -4.14340019e-01,\n",
      "         4.33867984e-03, -2.61205494e-01,  2.32519239e-01,\n",
      "         3.28712553e-01,  5.80756143e-02, -5.68789355e-02,\n",
      "         1.05924293e-01,  8.86878595e-02, -1.12380534e-02,\n",
      "        -4.60946858e-01,  3.96973819e-01,  4.99802947e-01,\n",
      "        -7.98294321e-03,  2.43046463e-01, -1.21099249e-01,\n",
      "        -3.94934446e-01, -5.71005270e-02,  3.94723378e-02,\n",
      "         3.05115700e-01, -2.42861256e-01, -1.29412562e-01,\n",
      "         1.97173208e-01,  2.22134769e-01]], dtype=float32), h=array([[ 2.79120624e-01,  2.27016836e-01, -3.55733857e-02,\n",
      "         2.46515244e-01,  6.28198236e-02, -3.87228988e-02,\n",
      "        -7.09124207e-02,  2.99940467e-01, -9.28423703e-02,\n",
      "        -3.84566367e-01, -2.14992501e-02,  5.85507648e-03,\n",
      "        -1.30961435e-02, -6.96759596e-02, -5.65687828e-02,\n",
      "        -8.50421786e-02, -2.43707523e-02, -9.16679800e-02,\n",
      "        -2.21135244e-01, -9.42663029e-02, -3.66907597e-01,\n",
      "         1.81497231e-01,  1.23043694e-01,  2.87678931e-02,\n",
      "        -4.91177291e-03, -6.10597692e-02,  8.68600905e-02,\n",
      "         1.14701577e-01, -6.74890950e-02,  8.59539732e-02,\n",
      "         8.75780135e-02, -2.01522792e-03,  1.35105610e-01,\n",
      "        -1.45157769e-01,  1.57687679e-01,  2.18709797e-01,\n",
      "        -3.17838788e-02, -1.68728679e-01, -1.28113389e-01,\n",
      "        -1.43630117e-01,  3.13521996e-02,  1.70731828e-01,\n",
      "        -2.00207725e-01,  1.81704927e-02,  1.85034767e-01,\n",
      "         2.95587368e-02, -2.46918812e-01, -8.45159963e-03,\n",
      "         5.38774990e-02, -1.92566425e-01,  1.79826573e-01,\n",
      "        -2.75095940e-01,  3.03090215e-02, -1.55220747e-01,\n",
      "         1.06272116e-01,  7.43305252e-04,  4.39021826e-01,\n",
      "         8.31100941e-02,  5.29124811e-02,  8.02120417e-02,\n",
      "        -7.36798421e-02,  1.61463529e-01, -1.20523475e-01,\n",
      "         1.05989255e-01, -8.98585171e-02, -1.61101431e-01,\n",
      "        -4.24000770e-02,  1.04560681e-01,  2.01972052e-01,\n",
      "        -1.22039199e-01,  3.16199064e-01,  1.54279202e-01,\n",
      "         4.84583676e-02, -3.12175333e-01,  3.38881984e-02,\n",
      "         7.64752701e-02, -2.46722996e-01, -4.42984067e-02,\n",
      "         2.37974394e-02,  9.67234001e-02,  4.59138989e-01,\n",
      "        -2.34253824e-01, -1.06248632e-01,  2.38263324e-01,\n",
      "        -8.06544796e-02, -8.17320198e-02, -2.57209241e-01,\n",
      "        -8.23990703e-02, -1.47125423e-02,  7.19822496e-02,\n",
      "        -5.79180904e-02,  6.07340448e-02, -1.52376860e-01,\n",
      "        -2.51730561e-01,  8.19027200e-02, -3.35132688e-01,\n",
      "         2.18787100e-02, -8.51504430e-02,  1.30140558e-01,\n",
      "         2.90624611e-03, -1.26077995e-01,  1.00510404e-01,\n",
      "         8.03042948e-02,  2.17386931e-01, -2.81329751e-01,\n",
      "         9.41741094e-02, -2.12147370e-01,  3.01339179e-01,\n",
      "        -2.17409972e-02, -2.78985724e-02, -2.81111877e-02,\n",
      "         3.27419676e-02,  1.12525113e-01, -3.23878638e-02,\n",
      "        -1.60936639e-01,  7.05522150e-02,  1.38506860e-01,\n",
      "         5.79616688e-02,  1.05685972e-01, -1.56362504e-01,\n",
      "        -2.00417072e-01,  2.24854395e-01,  4.19824153e-01,\n",
      "         8.29286203e-02, -9.35121924e-02,  1.42814443e-01,\n",
      "         6.76038191e-02, -6.14656098e-02],\n",
      "       [ 1.23194918e-01,  5.29380627e-02, -2.40595471e-02,\n",
      "         8.08865502e-02,  3.74177061e-02,  1.45174417e-04,\n",
      "        -1.14647500e-01,  8.33015069e-02, -6.33902475e-02,\n",
      "        -1.50905907e-01, -2.33877767e-02,  1.45718073e-02,\n",
      "         1.56418066e-02, -2.62452979e-02, -2.52938345e-02,\n",
      "        -5.28066419e-02,  2.74811732e-03, -2.27123555e-02,\n",
      "        -9.77179110e-02, -5.58866113e-02, -1.10998116e-01,\n",
      "         6.58477694e-02,  6.76694661e-02,  1.80645194e-02,\n",
      "         2.78699119e-03, -2.84228101e-02,  5.96616007e-02,\n",
      "         2.26764642e-02, -7.37615079e-02,  4.50607240e-02,\n",
      "         1.62934847e-02,  1.08686676e-02,  1.96677633e-02,\n",
      "        -6.14238381e-02,  7.60214776e-02,  6.68511614e-02,\n",
      "        -1.91089902e-02, -2.09966432e-02, -1.21235410e-02,\n",
      "        -4.30660769e-02, -2.18081251e-02,  1.13750808e-01,\n",
      "        -1.20869257e-01,  2.25687101e-02,  1.00368939e-01,\n",
      "         2.32241601e-02, -1.13223694e-01, -1.50189791e-02,\n",
      "         2.82276906e-02, -1.03612415e-01,  8.46927091e-02,\n",
      "        -5.90823367e-02,  4.67303768e-03, -2.52756868e-02,\n",
      "         4.69448827e-02,  5.71330078e-03,  1.51334062e-01,\n",
      "         9.76523012e-02,  5.75284623e-02, -2.04048175e-02,\n",
      "        -1.41300345e-02,  8.86563584e-03, -9.66379717e-02,\n",
      "         5.15859835e-02, -4.80995793e-03, -5.38436659e-02,\n",
      "        -3.59252468e-02,  1.23810172e-02,  8.55479911e-02,\n",
      "        -8.11769739e-02,  7.14197680e-02,  1.08848922e-01,\n",
      "        -2.16661002e-02, -6.53878674e-02,  2.80601270e-02,\n",
      "         4.54273522e-02, -7.49573931e-02, -4.23903354e-02,\n",
      "        -8.30341130e-03,  2.97778845e-02,  9.72278267e-02,\n",
      "        -8.35507512e-02, -6.57511689e-03,  6.30307868e-02,\n",
      "        -1.10726081e-01, -2.59534996e-02, -7.31021613e-02,\n",
      "        -3.76212820e-02, -2.52010059e-02,  3.03048138e-02,\n",
      "         2.23739110e-02,  3.99512947e-02, -1.05991222e-01,\n",
      "        -1.52217120e-01,  1.14497999e-02, -8.08032230e-02,\n",
      "         5.38733378e-02, -1.09266736e-01,  4.82565835e-02,\n",
      "        -2.12064944e-02, -1.26767859e-01,  7.62640983e-02,\n",
      "         1.74740329e-03,  5.54108582e-02, -2.21943054e-02,\n",
      "         6.55339379e-03, -9.42333788e-02,  6.39055893e-02,\n",
      "        -5.16633764e-02, -5.74231008e-03, -3.88724506e-02,\n",
      "         2.39470080e-02,  4.04750407e-02, -6.21582195e-02,\n",
      "        -4.41218875e-02,  2.38253158e-02,  1.37237117e-01,\n",
      "         7.68018328e-03,  2.11440232e-02, -6.41424805e-02,\n",
      "        -1.44708380e-01,  1.00386754e-01,  9.94592160e-02,\n",
      "         4.18722210e-03, -2.82707829e-02,  8.70669112e-02,\n",
      "         2.15412118e-02, -2.74325721e-02],\n",
      "       [ 3.33990961e-01,  2.81006038e-01, -6.14341348e-02,\n",
      "         3.11370254e-01,  8.24999139e-02, -2.96881720e-02,\n",
      "        -1.56252354e-01,  3.19033772e-01, -1.45743594e-01,\n",
      "        -4.09259021e-01, -4.20124345e-02,  1.17050642e-02,\n",
      "        -1.38963228e-02, -7.99942017e-02, -7.93107152e-02,\n",
      "        -1.02642864e-01, -3.71457860e-02, -1.20600991e-01,\n",
      "        -2.55015433e-01, -1.29454598e-01, -3.96239907e-01,\n",
      "         2.40877643e-01,  1.93839237e-01,  1.08841090e-02,\n",
      "        -5.17270947e-03, -9.52291265e-02,  1.22016169e-01,\n",
      "         1.40307322e-01, -8.91039371e-02,  1.28779814e-01,\n",
      "         4.65301424e-02, -2.98644090e-03,  1.33195728e-01,\n",
      "        -1.70877144e-01,  2.25119770e-01,  2.44242117e-01,\n",
      "        -3.56977433e-02, -1.98933885e-01, -1.58224270e-01,\n",
      "        -1.80869624e-01,  1.30170854e-02,  2.24719897e-01,\n",
      "        -2.49698892e-01,  3.36676873e-02,  1.97123840e-01,\n",
      "         3.28658260e-02, -2.98533440e-01, -1.41250826e-02,\n",
      "         6.48802146e-02, -2.52443910e-01,  2.27083370e-01,\n",
      "        -2.69491971e-01,  3.75877135e-02, -1.78166077e-01,\n",
      "         1.41202152e-01, -4.83001489e-03,  4.78133857e-01,\n",
      "         1.36233732e-01,  8.23827609e-02,  6.25189617e-02,\n",
      "        -8.25352222e-02,  1.47710606e-01, -1.88521981e-01,\n",
      "         1.56765252e-01, -1.06942460e-01, -1.93463936e-01,\n",
      "        -8.44436437e-02,  1.16948761e-01,  2.63495654e-01,\n",
      "        -1.96059018e-01,  3.26018512e-01,  2.24057302e-01,\n",
      "         5.11628352e-02, -2.94341564e-01,  2.37409603e-02,\n",
      "         9.28222388e-02, -2.91981757e-01, -5.63853644e-02,\n",
      "         3.07997838e-02,  1.01737209e-01,  4.42913026e-01,\n",
      "        -2.66615570e-01, -1.17642984e-01,  2.19076514e-01,\n",
      "        -1.51228935e-01, -4.33975123e-02, -2.88351983e-01,\n",
      "        -8.69935825e-02, -3.07685882e-02,  1.01225972e-01,\n",
      "        -4.11470644e-02,  1.17297634e-01, -2.38553092e-01,\n",
      "        -3.05832446e-01,  8.05909410e-02, -3.24360758e-01,\n",
      "         4.09302935e-02, -1.44942045e-01,  1.74173146e-01,\n",
      "         1.54998293e-02, -2.03197971e-01,  1.57225490e-01,\n",
      "         3.09413485e-02,  2.60894567e-01, -2.80064940e-01,\n",
      "         8.72433931e-02, -2.78748423e-01,  2.77426332e-01,\n",
      "        -2.24569924e-02, -2.49957237e-02, -7.30210543e-02,\n",
      "         6.61024004e-02,  1.25260502e-01, -6.23126999e-02,\n",
      "        -1.99795306e-01,  1.00193113e-01,  2.45569989e-01,\n",
      "         6.01142608e-02,  1.23521909e-01, -2.28508055e-01,\n",
      "        -2.50598282e-01,  2.54450262e-01,  4.04262900e-01,\n",
      "         1.23049296e-01, -1.13521852e-01,  1.74858212e-01,\n",
      "         7.59853572e-02, -3.56459804e-02],\n",
      "       [ 1.81219444e-01,  1.03499614e-01, -1.03989378e-01,\n",
      "         1.73168540e-01, -4.68093995e-03,  2.53995825e-02,\n",
      "        -1.61135405e-01,  2.15402424e-01, -1.46544546e-01,\n",
      "        -1.89591527e-01, -2.95443274e-02,  3.08058579e-02,\n",
      "        -6.53270930e-02, -1.16249710e-01, -2.85744704e-02,\n",
      "         8.25286880e-02, -2.98933368e-02, -5.84970415e-02,\n",
      "        -1.28505185e-01, -7.65275508e-02, -2.58883566e-01,\n",
      "         1.50517717e-01,  1.64263919e-01, -6.36459216e-02,\n",
      "        -5.77352643e-02, -1.32732332e-01,  3.45904604e-02,\n",
      "         1.41492724e-01,  3.99694033e-02,  8.56362656e-02,\n",
      "        -6.79800659e-02, -4.49486114e-02,  1.70436502e-01,\n",
      "        -9.57255289e-02,  1.67286605e-01,  1.80024803e-01,\n",
      "        -1.44634591e-02, -1.90305412e-01, -1.55330300e-01,\n",
      "        -1.88807830e-01,  1.72686130e-02,  1.29135385e-01,\n",
      "        -1.53915435e-01,  1.77457482e-02, -4.02246714e-02,\n",
      "        -6.65146112e-02, -1.60031289e-01,  2.44003348e-02,\n",
      "         1.33182174e-02, -1.60195872e-01,  1.11959718e-01,\n",
      "        -2.28284001e-01, -1.68327037e-02, -1.27156183e-01,\n",
      "         1.67169973e-01, -9.92493480e-02,  1.51914775e-01,\n",
      "         7.15445802e-02, -3.80531028e-02,  9.31239575e-02,\n",
      "        -8.27673823e-02,  1.57192171e-01, -1.47627100e-01,\n",
      "         1.02286488e-01, -1.61129132e-01, -1.48906887e-01,\n",
      "        -8.50799382e-02,  1.89215511e-01,  1.51778087e-01,\n",
      "        -1.28526062e-01,  2.07559377e-01,  1.89455271e-01,\n",
      "         1.64949283e-01, -1.90596655e-01, -6.07417151e-02,\n",
      "        -8.71976316e-02, -1.76272780e-01,  8.11125487e-02,\n",
      "         8.12813118e-02,  1.18638389e-01,  2.11488292e-01,\n",
      "        -2.70634759e-02, -8.12876374e-02,  2.50902623e-02,\n",
      "        -1.44269615e-01,  5.08600399e-02, -1.22341752e-01,\n",
      "        -1.79703571e-02, -5.29825278e-02,  1.66078851e-01,\n",
      "        -9.32513699e-02, -5.11687286e-02, -2.28673428e-01,\n",
      "         5.32761253e-02,  1.05911888e-01, -2.16404304e-01,\n",
      "        -5.31067848e-02,  6.84734434e-02,  1.61587104e-01,\n",
      "         1.30051211e-01, -9.64871719e-02,  1.16388619e-01,\n",
      "        -9.24600959e-02,  2.20458522e-01, -2.24125028e-01,\n",
      "         2.48689251e-03, -1.22045308e-01,  1.24818735e-01,\n",
      "         1.31797552e-01,  2.43399907e-02, -2.75500230e-02,\n",
      "         5.04521281e-02,  4.00709733e-02, -4.66669211e-03,\n",
      "        -2.11343318e-01,  1.60463855e-01,  2.01137990e-01,\n",
      "        -3.84287653e-03,  1.36976525e-01, -6.92986622e-02,\n",
      "        -1.54117450e-01, -3.30059193e-02,  2.26557571e-02,\n",
      "         1.64121076e-01, -1.22921921e-01, -6.01741001e-02,\n",
      "         8.12154710e-02,  1.11656733e-01]], dtype=float32)), LSTMStateTuple(c=array([[ 0.11587894, -0.01081529, -0.00926025, ...,  0.02874609,\n",
      "        -0.05872983, -0.05541277],\n",
      "       [ 0.08372056, -0.00823283, -0.02095547, ...,  0.02793321,\n",
      "        -0.04521082, -0.05605091],\n",
      "       [ 0.1811778 , -0.02092076, -0.02060957, ...,  0.05882005,\n",
      "        -0.10283944, -0.10466262],\n",
      "       [ 0.1074626 , -0.03412552, -0.0153853 , ...,  0.03540574,\n",
      "        -0.03398335, -0.06367162]], dtype=float32), h=array([[ 0.06101465, -0.00499493, -0.00471805, ...,  0.01425603,\n",
      "        -0.02972551, -0.02672425],\n",
      "       [ 0.04229382, -0.00407521, -0.01046767, ...,  0.01387198,\n",
      "        -0.02256514, -0.02741067],\n",
      "       [ 0.09486194, -0.00958257, -0.01041569, ...,  0.02924553,\n",
      "        -0.05174449, -0.05033881],\n",
      "       [ 0.05584113, -0.01584079, -0.00768016, ...,  0.01812207,\n",
      "        -0.01703749, -0.03205018]], dtype=float32)))\n"
     ]
    }
   ],
   "source": [
    "print(outputs_val)\n",
    "print(outputs_val.shape) #(4, 2, 256)\n",
    "print(states_val) #tuple\n",
    "#outputs_val and states_val[1].h will be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 128)\n",
      "(4, 256)\n",
      "(4, 128)\n",
      "(4, 256)\n"
     ]
    }
   ],
   "source": [
    "print(states_val[0].c.shape)\n",
    "print(states_val[1].c.shape)\n",
    "print(states_val[0].h.shape)\n",
    "print(states_val[1].h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'rnn/multi_rnn_cell/cell_0/lstm_cell/kernel:0' shape=(131, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_0/lstm_cell/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_1/lstm_cell/kernel:0' shape=(384, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_1/lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Variable Length Input Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "n_neurons = 5\n",
    "n_inputs = 3\n",
    "n_steps =2\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "seq_length = tf.placeholder(tf.int32, [None])\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units = n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32, sequence_length= seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_batch = np.array([\n",
    "    [[0,1,2],[9,8,7]], #instance 0 \n",
    "    [[3,4,5],[0,0,0]], #instance 1\n",
    "    [[6,7,8],[6,5,4]], #instance 2\n",
    "    [[9,0,1],[3,2,1]], #instance 3\n",
    "])\n",
    "\n",
    "seq_length_batch = np.array([2,1,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val, states_val = sess.run([outputs, states], feed_dict={X: X_batch, seq_length:seq_length_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(states_val)\n",
    "#Second row is only for t=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Sequence Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_steps = 28\n",
    "n_inputs = 28\n",
    "n_neurons = 150\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate =0.001"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We will use cells of 150 recurrent neurons plus a fully-connected later containing 10 neurons (one per class) connected to the output of the last time step, followed by a softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X =  tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int64, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
    "#dimensionality of states is batch_size X n_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf.layers.dense adds a single layer to your network. The second argument is the number of neurons/nodes of the layer\n",
    "logits = tf.layers.dense(inputs = states, units = n_outputs)\n",
    "#Output tensor the same shape as inputs except the last dimension is of size units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits = logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "training = optimizer.minimize(loss)\n",
    "correct = tf.nn.in_top_k(logits,y,1)\n",
    "#correct = tf.equal(tf.argmax(logits, 1), y)\n",
    "accuracy =tf.reduce_mean(tf.cast(correct,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets(\"tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.train.images.reshape((-1, n_steps, n_inputs)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = mnist.test.images.reshape((-1, n_steps, n_inputs))\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size =50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iterations in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            X_batch = X_batch.reshape((-1, n_steps, n_inputs))\n",
    "            sess.run(training, feed_dict={X: X_batch, y: y_batch})\n",
    "            states_val = states.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(epoch, \"Train Accuracy: \", acc_train, \"Test Accuracy: \", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you do convert labels into one-hot vector, this is what you should do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "#import mnist dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist=input_data.read_data_sets(\"/tmp/data/\",one_hot=True)\n",
    "\n",
    "#define constants\n",
    "#unrolled through 28 time steps\n",
    "time_steps=28\n",
    "#hidden LSTM units\n",
    "num_units=128\n",
    "#rows of 28 pixels\n",
    "n_input=28\n",
    "#learning rate for adam\n",
    "learning_rate=0.001\n",
    "#mnist is meant to be classified in 10 classes(0-9).\n",
    "n_classes=10\n",
    "#size of batch\n",
    "batch_size=128\n",
    "\n",
    "#Lets now declare placeholders and weights and bias variables which will be used to convert the output of shape \n",
    "#[batch_size,num_units] to [batch_size,n_classes] so that correct class can be predicted.\n",
    "\n",
    "#weights and biases of appropriate shape to accomplish above task\n",
    "out_weights=tf.Variable(tf.random_normal([num_units,n_classes]))\n",
    "out_bias=tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "#defining placeholders\n",
    "#input image placeholder\n",
    "x=tf.placeholder(\"float\",[None,time_steps,n_input])\n",
    "#input label placeholder\n",
    "y=tf.placeholder(\"float\",[None,n_classes])\n",
    "\n",
    "#Now that we are receiving inputs of shape [batch_size,time_steps,n_input],we need to convert it into a list of \n",
    "#tensors of shape [batch_size,n_inputs] of length time_steps so that it can be then fed to static_rnn.\n",
    "\n",
    "#processing the input tensor from [batch_size,n_steps,n_input] to \"time_steps\" number of [batch_size,n_input] tensors\n",
    "input=tf.unstack(x ,time_steps,1)\n",
    "\n",
    "lstm_layer=rnn.BasicLSTMCell(num_units,forget_bias=1)\n",
    "outputs,_=rnn.static_rnn(lstm_layer,input,dtype=\"float32\")\n",
    "\n",
    "#converting last output of dimension [batch_size,num_units] to [batch_size,n_classes] by out_weight multiplication\n",
    "prediction=tf.matmul(outputs[-1],out_weights)+out_bias\n",
    "\n",
    "loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y))\n",
    "#optimization\n",
    "opt=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "#model evaluation\n",
    "correct_prediction=tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "#initialize variables\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    iter=1\n",
    "    while iter<800:\n",
    "        batch_x,batch_y=mnist.train.next_batch(batch_size=batch_size)\n",
    "\n",
    "        batch_x=batch_x.reshape((batch_size,time_steps,n_input))\n",
    "\n",
    "        sess.run(opt, feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "        if iter %10==0:\n",
    "            acc=sess.run(accuracy,feed_dict={x:batch_x,y:batch_y})\n",
    "            los=sess.run(loss,feed_dict={x:batch_x,y:batch_y})\n",
    "            print(\"For iter \",iter)\n",
    "            print(\"Accuracy \",acc)\n",
    "            print(\"Loss \",los)\n",
    "            print(\"__________________\")\n",
    "\n",
    "        iter=iter+1\n",
    "    #calculating test accuracy\n",
    "    test_data = mnist.test.images[:128].reshape((-1, time_steps, n_input))\n",
    "    test_label = mnist.test.labels[:128]\n",
    "    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: test_data, y: test_label}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training to predict Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the RNN. It will contain 100 recurrent neurons and we will unroll it over 20 time steps since each traiing instance will be 20 inputs long. Each input will contain only one feature (the value at that time). The targets are also sequences of 20 inputs, each containing a single value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_steps = 20\n",
    "n_neurons =100\n",
    "n_inputs = 1\n",
    "n_outputs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_min, t_max  = 0, 30\n",
    "resolution = 0.1\n",
    "\n",
    "def time_series(t):\n",
    "    return t * np.sin(t) / 3 + 2 * np.sin(t*5)\n",
    "\n",
    "def next_batch(batch_size, n_steps):\n",
    "    t0 = np.random.rand(batch_size, 1) * (t_max - t_min - n_steps * resolution)\n",
    "    Ts = t0 + np.arange(0., n_steps + 1) * resolution\n",
    "    ys = time_series(Ts)\n",
    "    return ys[:, :-1].reshape(-1, n_steps, 1), ys[:, 1:].reshape(-1, n_steps, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "t = np.linspace(t_min, t_max, int((t_max - t_min) / resolution))\n",
    "\n",
    "n_steps = 20\n",
    "t_instance = np.linspace(12.2, 12.2 + resolution * (n_steps + 1), n_steps + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_batch, y_batch = next_batch(1, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each time step we now have an output vector of size 100 (because we have 100 neurons. Yt will be batch_size X n_neurons). But what we actually want is a single output value at each time step. The simplest solution is to wrap the cell in an OutputProjectionWrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X= tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])\n",
    "cell = tf.contrib.rnn.OutputProjectionWrapper(tf.contrib.rnn.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu), output_size=n_outputs)\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(outputs - y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "n_iterations = 1500\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for iteration in range(n_iterations):\n",
    "        X_batch, y_batch = next_batch(batch_size, n_steps)\n",
    "        sess.run(training, feed_dict={X:X_batch, y:y_batch})\n",
    "        if iteration % 100 == 0:\n",
    "            mse = loss.eval(feed_dict={X:X_batch, y:y_batch})\n",
    "            print(iteration, \"\\tMSE\", mse)\n",
    "    saver.save(sess, \"./my_time_series_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:                          \n",
    "    saver.restore(sess, \"./my_time_series_model\")   \n",
    "    X_new = time_series(np.array(t_instance[:-1].reshape(-1, n_steps, n_inputs)))\n",
    "    y_pred = sess.run(outputs, feed_dict={X: X_new})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without using an OutputProjectionWrapper¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "n_steps = 20\n",
    "n_inputs = 1\n",
    "n_neurons = 100\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])\n",
    "\n",
    "cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu)\n",
    "rnn_outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "\n",
    "n_outputs = 1\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons])\n",
    "stacked_outputs = tf.layers.dense(stacked_rnn_outputs, n_outputs)\n",
    "outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])\n",
    "#in the last line, the outputs is reshaped to [batch_size X n_steps X n_outputs] because in the loss function below,\n",
    "#we will find squared mean root and y placeholder is shaped as [None, n_steps, n_outputs]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(outputs - y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "n_iterationsn_iterat  = 1500\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for iteration in range(n_iterations):\n",
    "        X_batch, y_batch = next_batch(batch_size, n_steps)\n",
    "        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if iteration % 100 == 0:\n",
    "            mse = loss.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            print(iteration, \"\\tMSE:\", mse)\n",
    "    \n",
    "    X_new = time_series(np.array(t_instance[:-1].reshape(-1, n_steps, n_inputs)))\n",
    "    y_pred = sess.run(outputs, feed_dict={X: X_new})\n",
    "    \n",
    "    saver.save(sess, \"./my_time_series_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiRNNCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 2\n",
    "n_steps = 5\n",
    "\n",
    "import tensorflow as tf \n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_neurons = 100\n",
    "n_layers = 3\n",
    "\n",
    "import numpy as np\n",
    "layers = [tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "          for layer in range(n_layers)]\n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(layers)\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_batch = np.random.rand(2, n_steps, n_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with  tf.Session() as sess:\n",
    "         init.run()\n",
    "         outputs_val, states_val = sess.run([outputs, states], feed_dict={X: X_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#outputs_val[0] #first instance (batch =0)\n",
    "#outputs_val[0][0] - outputs_val[0][4] # first instance and 5 time steps\n",
    "#outputs_val[0][0][0] - outputs_val[0][0][99] # first instance and first time step and 100 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs_val.shape\n",
    "#2 instances, 5 times steps, 100 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#states_val[0] - states_val[2] #number of layers\n",
    "#states_val[0][0] - states_val[0][1]   #first layer, 2 instances\n",
    "\n",
    "#states_val[0][0][0] - states_val[0][0][99] #first layer first instance and 100 neurons\n",
    "#final states of each cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a LSTM to predict the next word using a sample short story, Aesop’s Fables (DEEP RNN)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "long ago , the mice had a general council to consider what measures they could take to outwit their common enemy , the cat . some said this , and some said that but at last a young mouse got up and said he had a proposal to make , which he thought would meet the case . you will all agree , said he , that our chief danger consists in the sly and treacherous manner in which the enemy approaches us . now , if we could receive some signal of her approach , we could easily escape from her . i venture , therefore , to propose that a small bell be procured , and attached by a ribbon round the neck of the cat . by this means we should always know when she was about , and could easily retire while she was in the neighbourhood . this proposal met with general applause , until an old mouse got up and said  that is all very well , but who is to bell the cat ? the mice looked at one another and nobody spoke . then the old mouse said it is easy to propose impossible remedies ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import random\n",
    "import collections\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "def elapsed(sec):\n",
    "    if sec<60:\n",
    "        return str(sec) + \" sec\"\n",
    "    elif sec<(60*60):\n",
    "        return str(sec/60) + \" min\"\n",
    "    else:\n",
    "        return str(sec/(60*60)) + \" hr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we feed a LSTM with correct sequences from the text of 3 symbols as inputs and 1 labeled symbol, eventually the neural network will learn to predict the next symbol correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Target log path\n",
    "logs_path = '/Users/mustafamuratarat'\n",
    "writer = tf.summary.FileWriter(logs_path)\n",
    "\n",
    "# Text file containing words for training\n",
    "training_file = '/Users/mustafamuratarat/belling_the_cat.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(fname):\n",
    "    with open(fname) as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    content = [word for i in range(len(content)) for word in content[i].split()]\n",
    "    content = np.array(content)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = read_data(training_file)\n",
    "print(\"Loaded training data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically, LSTM inputs can only understand real numbers. A way to convert symbol to number is to assign a unique integer to each symbol based on frequency of occurrence. For example, there are 112 unique symbols in the text above. The function 'build_dataset' builds a dictionary with the following entries [ “,” : 0 ] [ “the” : 1 ], …, [ “council” : 37 ],…,[ “spoke” : 111 ]. The reverse dictionary is also generated since it will be used in decoding the output of LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_dataset(words):\n",
    "    count = collections.Counter(words).most_common()\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return dictionary, reverse_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary, reverse_dictionary = build_dataset(training_data)\n",
    "vocab_size = len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the prediction is a unique integer identifying the index in the reverse dictionary of the predicted symbol. For example, if the prediction is 37, the predicted symbol is actually “council”.\n",
    "\n",
    "The generation of output may sound simple but actually LSTM produces a 112-element vector (because vocab_size is 112) of probabilities of prediction for the next symbol normalized by the softmax() function. The index of the element with the highest probability is the predicted index of the symbol in the reverse dictionary (ie a one-hot vector). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We are feeding 3 words at each time steps\n",
    "n_input = 3\n",
    "\n",
    "# number of units in RNN cell (basically n_neurons)\n",
    "n_hidden = 512\n",
    "\n",
    "display_step = 1000\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 50000\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input, 1])\n",
    "y = tf.placeholder(\"float\", [None, vocab_size])\n",
    "\n",
    "# RNN output node weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, vocab_size]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([vocab_size]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # reshape to [1, n_input]\n",
    "    x = tf.reshape(x, [-1, n_input])\n",
    "\n",
    "    # Generate a n_input-element sequence of inputs\n",
    "    # (eg. [had] [a] [general] -> [20] [6] [33])\n",
    "    x = tf.split(x,n_input,1)\n",
    "\n",
    "    # 2-layer LSTM, each layer has n_hidden units.\n",
    "    # Average Accuracy= 95.20% at 50k iter\n",
    "    rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(n_hidden),rnn.BasicLSTMCell(n_hidden)])\n",
    "\n",
    "    # 1-layer LSTM with n_hidden units but with lower accuracy.\n",
    "    # Average Accuracy= 90.60% 50k iter\n",
    "    # Uncomment line below to test but comment out the 2-layer rnn.MultiRNNCell above\n",
    "    # rnn_cell = rnn.BasicLSTMCell(n_hidden)\n",
    "\n",
    "    # generate prediction\n",
    "    outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # there are n_input outputs but\n",
    "    # we only want the last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "pred = RNN(x, weights, biases)\n",
    "\n",
    "# Loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Model evaluation\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    step = 0\n",
    "    offset = random.randint(0,n_input+1)\n",
    "    end_offset = n_input + 1\n",
    "    acc_total = 0\n",
    "    loss_total = 0\n",
    "\n",
    "    writer.add_graph(session.graph)\n",
    "\n",
    "    while step < training_iters:\n",
    "        # Generate a minibatch. Add some randomness on selection process.\n",
    "        if offset > (len(training_data)-end_offset):\n",
    "            offset = random.randint(0, n_input+1)\n",
    "#In the training process, at each step, 3 symbols are retrieved from the training data. \n",
    "#These 3 symbols are converted to integers to form the input vector.\n",
    "        symbols_in_keys = [ [dictionary[ str(training_data[i])]] for i in range(offset, offset+n_input) ]\n",
    "        symbols_in_keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
    "\n",
    "#The training label is a one-hot vector coming from the symbol after the 3 input symbols.\n",
    "        symbols_out_onehot = np.zeros([vocab_size], dtype=float)\n",
    "        symbols_out_onehot[dictionary[str(training_data[offset+n_input])]] = 1.0\n",
    "        symbols_out_onehot = np.reshape(symbols_out_onehot,[1,-1])\n",
    "\n",
    "        _, acc, loss, onehot_pred = session.run([optimizer, accuracy, cost, pred], \\\n",
    "                                                feed_dict={x: symbols_in_keys, y: symbols_out_onehot})\n",
    "        loss_total += loss\n",
    "        acc_total += acc\n",
    "        if (step+1) % display_step == 0:\n",
    "            print(\"Iter= \" + str(step+1) + \", Average Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss_total/display_step) + \", Average Accuracy= \" + \\\n",
    "                  \"{:.2f}%\".format(100*acc_total/display_step))\n",
    "            acc_total = 0\n",
    "            loss_total = 0\n",
    "            symbols_in = [training_data[i] for i in range(offset, offset + n_input)]\n",
    "            symbols_out = training_data[offset + n_input]\n",
    "            symbols_out_pred = reverse_dictionary[int(tf.argmax(onehot_pred, 1).eval())]\n",
    "            print(\"%s - [%s] vs [%s]\" % (symbols_in,symbols_out,symbols_out_pred))\n",
    "        step += 1\n",
    "        offset += (n_input+1)\n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Elapsed time: \", elapsed(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you build a very deep RNN, it may end up overfitting the training set. In order to prevent that, a common technique is to apply dropout. You can simply add a dropout layer before or after the RNN as usual but if you also want to apply dropout between RNN layers, you need to use a DropoutWrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_min, t_max  = 0, 30\n",
    "resolution = 0.1\n",
    "\n",
    "def time_series(t):\n",
    "    return t * np.sin(t) / 3 + 2 * np.sin(t*5)\n",
    "\n",
    "def next_batch(batch_size, n_steps):\n",
    "    t0 = np.random.rand(batch_size, 1) * (t_max - t_min - n_steps * resolution)\n",
    "    Ts = t0 + np.arange(0., n_steps + 1) * resolution\n",
    "    ys = time_series(Ts)\n",
    "    return ys[:, :-1].reshape(-1, n_steps, 1), ys[:, 1:].reshape(-1, n_steps, 1)\n",
    "\n",
    "import numpy as np\n",
    "t = np.linspace(t_min, t_max, int((t_max - t_min) / resolution))\n",
    "\n",
    "n_steps = 20\n",
    "t_instance = np.linspace(12.2, 12.2 + resolution * (n_steps + 1), n_steps + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 1\n",
    "n_neurons = 100\n",
    "n_layers = 3\n",
    "n_steps = 20\n",
    "n_outputs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "X  = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the input_keep_prob parameter can be a placeholder, making it possible to set it to any value you want during training, and to 1.0 during testing (effectively turning dropout off)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder_with_default(1.0, shape=())\n",
    "cells = [tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "         for layer in range(n_layers)]\n",
    "cells_drop = [tf.contrib.rnn.DropoutWrapper(cell, input_keep_prob=keep_prob)\n",
    "              for cell in cells]\n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(cells_drop)\n",
    "rnn_outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons])\n",
    "stacked_outputs = tf.layers.dense(stacked_rnn_outputs, n_outputs)\n",
    "outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(outputs - y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, you can feed any value you want to the keep_prob placeholder (typically 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_iterations = 1500\n",
    "batch_size = 50\n",
    "train_keep_prob = 0.5\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for iteration in range(n_iterations):\n",
    "        X_batch, y_batch = next_batch(batch_size, n_steps)\n",
    "        _, mse = sess.run([training_op, loss],\n",
    "                          feed_dict={X: X_batch, y: y_batch,\n",
    "                                     keep_prob: train_keep_prob})\n",
    "        if iteration % 100 == 0:                 \n",
    "            print(iteration, \"Training MSE:\", mse) \n",
    "    \n",
    "    saver.save(sess, \"./my_dropout_time_series_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_dropout_time_series_model\")\n",
    "\n",
    "    X_new = time_series(np.array(t_instance[:-1].reshape(-1, n_steps, n_inputs)))\n",
    "    y_pred = sess.run(outputs, feed_dict={X: X_new})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred #20 time-steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "plt.title(\"Testing the model\", fontsize=14)\n",
    "plt.plot(t_instance[:-1], time_series(t_instance[:-1]), \"bo\", markersize=10, label=\"instance\")\n",
    "plt.plot(t_instance[1:], time_series(t_instance[1:]), \"w*\", markersize=10, label=\"target\")\n",
    "plt.plot(t_instance[1:], y_pred[0,:,0], \"r.\", markersize=10, label=\"prediction\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel(\"Time\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " it seems that Dropout does not help at all in this particular case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short Term Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_steps = 28\n",
    "n_inputs = 28\n",
    "n_neurons = 150\n",
    "n_outputs = 10\n",
    "n_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "import tensorflow as tf\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_cells = [tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons)\n",
    "              for layer in range(n_layers)]\n",
    "multi_cell = tf.contrib.rnn.MultiRNNCell(lstm_cells)\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_cell, X, dtype=tf.float32)\n",
    "top_layer_h_state = states[-1][1] #[batch_size X num_neurons]\n",
    "#top_layer_h_state is a tuple containing 3 LSTM layers, each with dimension batch_size X n_neurons\n",
    "#this part is not doing softmax even though it is named as \"softmax\". \n",
    "logits = tf.layers.dense(top_layer_h_state, n_outputs, name=\"softmax\")\n",
    "#the shape of logits is batch_size X n_outputs\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"tmp/data/\")\n",
    "X_test = mnist.test.images.reshape((-1, n_steps, n_inputs))\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            X_batch = X_batch.reshape((batch_size, n_steps, n_inputs))\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(\"Epoch\", epoch, \"Train accuracy =\", acc_train, \"Test accuracy =\", acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you want to use peephole connections in LSTM, you can do:\n",
    "lstm_cell = tf.contrib.rnn.LSTMCell(num_units=n_neurons, use_peepholes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use GRU cell, you can do:\n",
    "gru_cell = tf.contrib.rnn.GRUCell(num_units=n_neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary String LSTM Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a binary string (a string with just 0s and 1s) of length 20, we need to determine the count of 1s in a binary string. For example, “01010010011011100110” has 11 ones. So the input for our program will be a string of length twenty that contains 0s and 1s and the output must be a single number between 0 and 20 which represents the number of ones in the string http://monik.in/a-noobs-guide-to-implementing-rnn-lstm-using-tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    " \n",
    "train_input = ['{0:020b}'.format(i) for i in range(2**20)]\n",
    "shuffle(train_input)\n",
    "train_input = [map(int,i) for i in train_input]\n",
    "ti  = []\n",
    "for i in train_input:\n",
    "    temp_list = []\n",
    "    for j in i:\n",
    "            temp_list.append([j])\n",
    "    ti.append(np.array(temp_list))\n",
    "train_input = ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_output = []\n",
    " \n",
    "for i in train_input:\n",
    "    count = 0\n",
    "    for j in i:\n",
    "        if j[0] == 1:\n",
    "            count+=1\n",
    "    temp_list = ([0]*21)\n",
    "    temp_list[count]=1\n",
    "    train_output.append(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_EXAMPLES = 10000\n",
    "test_input = train_input[NUM_EXAMPLES:]\n",
    "test_output = train_output[NUM_EXAMPLES:] #everything beyond 10,000\n",
    " \n",
    "train_input = train_input[:NUM_EXAMPLES]\n",
    "train_output = train_output[:NUM_EXAMPLES] #till 10,000\n",
    "\n",
    "#output is one-hot encoded"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[\n",
    " array([[0],[0],[1],[0],[0],[1],[0],[1],[1],[0],[0],[0],[1],[1],[1],[1],[1],[1],[0],[0]]), \n",
    " array([[1],[1],[0],[0],[0],[0],[1],[1],[1],[1],[1],[0],[0],[1],[0],[0],[0],[1],[0],[1]]), \n",
    " .....\n",
    "]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    " 0  1  2  3  4  5  6  7  8  9  10 11 12 13 14 15 16 17 18 19 20\n",
    "This is a sample output for a sequence which belongs to 4th class i.e has 4 ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = train_input[0][0].shape[0] #1\n",
    "n_outputs = len(train_output[0]) #21\n",
    "n_steps = train_input[0].shape[0] #20\n",
    "n_neurons = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons, state_is_tuple=True, forget_bias=1.0)\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs= tf.transpose(outputs, [1, 0, 2])\n",
    "last = tf.gather(outputs, int(outputs.get_shape()[0]) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate= 0.01\n",
    "\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_neurons, int(y.get_shape()[1])]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.constant(0.1, shape=[y.get_shape()[1]]))\n",
    "}\n",
    "\n",
    "prediction = tf.matmul(last, weights['out'])+biases['out']\n",
    "loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y))\n",
    "#optimization\n",
    "opt=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "#model evaluation\n",
    "correct_prediction=tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "#mistakes = tf.not_equal(tf.argmax(y, 1), tf.argmax(prediction, 1))\n",
    "#error = tf.reduce_mean(tf.cast(mistakes, tf.float32))\n",
    "\n",
    "batch_size = 1000\n",
    "no_of_batches = int((len(train_input)) / batch_size)\n",
    "#initialize variables\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    iter=1\n",
    "    while iter<800:\n",
    "        ptr = 0\n",
    "        for j in range(no_of_batches):\n",
    "            inp, out = train_input[ptr:ptr+batch_size], train_output[ptr:ptr+batch_size]\n",
    "            ptr+=batch_size\n",
    "            sess.run(opt,feed_dict={X: inp, y: out})\n",
    "            if iter %10==0:\n",
    "                acc=sess.run(accuracy,feed_dict={X: inp, y: out})\n",
    "                los=sess.run(loss,feed_dict={X: inp, y: out})\n",
    "                print(\"For iter \",iter)\n",
    "                print(\"Accuracy \",acc)\n",
    "                print(\"Loss \",los)\n",
    "                print(\"__________________\")\n",
    "            iter=iter+1\n",
    "        #calculating test accuracy\n",
    "    print(\"Test Accuracy: \", sess.run(accuracy,{X:test_input, y:test_output }))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is based on TensorFlow's Word2Vec tutorial\n",
    "https://www.tensorflow.org/tutorials/representation/word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import urllib\n",
    "\n",
    "import errno\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "WORDS_PATH = \"datasets/words\"\n",
    "WORDS_URL = 'http://mattmahoney.net/dc/text8.zip'\n",
    "\n",
    "def mkdir_p(path):\n",
    "    \"\"\"Create directories, ok if they already exist.\n",
    "    \n",
    "    This is for python 2 support. In python >=3.2, simply use:\n",
    "    >>> os.makedirs(path, exist_ok=True)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "def fetch_words_data(words_url=WORDS_URL, words_path=WORDS_PATH):\n",
    "    os.makedirs(words_path, exist_ok=True)\n",
    "    zip_path = os.path.join(words_path, \"words.zip\")\n",
    "    if not os.path.exists(zip_path):\n",
    "        urllib.request.urlretrieve(words_url, zip_path)\n",
    "    with zipfile.ZipFile(zip_path) as f:\n",
    "        data = f.read(f.namelist()[0])\n",
    "    return data.decode(\"ascii\").split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = fetch_words_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
