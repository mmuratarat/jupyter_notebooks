{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import time\n",
    "import math\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (8,7)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(55000, 28, 28)\n",
      "(55000, 10)\n",
      "(10000, 28, 28)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#Data parameters\n",
    "num_inputs = 28\n",
    "num_classes = 10\n",
    "num_steps=28\n",
    "\n",
    "old_v = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#Data parameters\n",
    "num_inputs = 28\n",
    "num_classes = 10\n",
    "num_steps=28\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "Xtrain = mnist.train.images  # Returns np.array\n",
    "Xtrain = Xtrain.reshape((-1, num_steps, num_inputs))\n",
    "ytrain = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "Xtest = mnist.test.images  # Returns np.array\n",
    "Xtest = Xtest.reshape([-1, num_steps, num_inputs])\n",
    "ytest = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "tf.logging.set_verbosity(old_v)\n",
    "\n",
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(Xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_variables(batch_size, cell):\n",
    "    \"\"\"Returns TF Variables for storing the cell and hidden states of an LSTM.\n",
    "    A stateful LSTM keeps its hidden and cell states after a forward propagation run and uses the\n",
    "    stored states in the next forward propagation run independently of the number of steps the\n",
    "    LSTM is unrolled for. For implementing such an LSTM in TF, you need to store the state in\n",
    "    variables. This function returns the state variables of an LSTM cell.\n",
    "    A comprehensive case for building a multilayer LSTM with a dynamic batch size and number of time\n",
    "    steps is given below:\n",
    "    inputs_one_hot = tf.one_hot(inputs, self.vocab_size)\n",
    "    # inputs_one_hot will have shape (batch_size, num_timesteps, vocab_size)\n",
    "    batch_size, num_timesteps = tf.shape(inputs_one_hot)[0], tf.shape(inputs_one_hot)[1]\n",
    "    # For each layer, get the initial state. state will be a tuple of LSTMStateTuples. Get\n",
    "    # the variables in their own scope so that, we can exclude them from being saved.\n",
    "    with tf.variable_scope(\"lstm_state\"):\n",
    "        state = get_state_variables(cell, max_batch_size)\n",
    "    # Unroll the LSTM\n",
    "    initial_state = get_state_variables_for_batch(state, batch_size)\n",
    "    rnn_outputs, new_state = tf.nn.dynamic_rnn(self._cell, inputs_one_hot,\n",
    "                                               initial_state=initial_state)\n",
    "    # Only get the outputs of the used batches\n",
    "    rnn_outputs = rnn_outputs[:batch_size]\n",
    "    # Add an operation to update the states with the last state tensors\n",
    "    self._update_state_op = get_state_update_op(state, new_state)\n",
    "    Args:\n",
    "        cell (tf.contrib.rnn.MultiRNNCell): An MultiRNNCell consisting of multiple LSTMCells.\n",
    "        max_batch_size (int): The maximum size of batches that are be fed to the LSTMCell. Each\n",
    "            state variable in the result tuple will have max_batch_size rows in the first dimension.\n",
    "    Returns:\n",
    "        tuple[tf.contrib.rnn.LSTMStateTuple]: A tuple of LSTMStateTuples. Each of those will contain\n",
    "            a zero cell and zero hidden state, each of shape [max_batch_size, state_size]. The\n",
    "            length of the result tuple will be determined by the cell's number of layers (e.g. for\n",
    "            an MultiRNNCell).\n",
    "    \"\"\"\n",
    "\n",
    "    # For each layer, get the initial state tuple and make two variables out of it to enable setting\n",
    "    # its value.\n",
    "    state_variables = []\n",
    "    for state_c, state_h in cell.zero_state(batch_size, tf.float32):\n",
    "        state_variables.append(tf.contrib.rnn.LSTMStateTuple(\n",
    "            tf.Variable(state_c, trainable=False),\n",
    "            tf.Variable(state_h, trainable=False)))\n",
    "    return tuple(state_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_update_op(state_variables, new_states):\n",
    "    \"\"\"Returns an operation to update an LSTM's state variables.\n",
    "    See get_state_variables() for more info.\n",
    "    Args:\n",
    "        state_variables (tuple[tf.contrib.rnn.LSTMStateTuple]): The LSTM's state variables.\n",
    "        new_states (tuple[tf.contrib.rnn.LSTMStateTuple]): The new values for the state variables.\n",
    "            new_states may have state tuples with state sizes < max_batch_size. Then, only the first\n",
    "            rows of the corresponding state variables will be updated.\n",
    "    Returns:\n",
    "        tf.Operation: An operation that updates the LSTM's.\n",
    "    \"\"\"\n",
    "\n",
    "    # Add an operation to update the train states with the last state tensors.\n",
    "    update_ops = []\n",
    "    for state_variable, new_state in zip(state_variables, new_states):\n",
    "        # new_state[0] might be smaller than state_variable[0], because state_variable[0]\n",
    "        # contains max_batch_size entries.\n",
    "\n",
    "        # Get the update indices for both states in the tuple\n",
    "        update_indices = (tf.range(0, tf.shape(new_state[0])[0]),\n",
    "                          tf.range(0, tf.shape(new_state[1])[0]))\n",
    "        update_ops.extend([\n",
    "            tf.scatter_update(state_variable[0], update_indices[0], new_state[0]),\n",
    "            tf.scatter_update(state_variable[1], update_indices[1], new_state[1])\n",
    "        ])\n",
    "    return tf.tuple(update_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_reset_op(state_variables, cell, batch_size):\n",
    "    \"\"\"Returns an operation to set each variable in a list of LSTMStateTuples to zero.\n",
    "    See get_state_variables() for more info.\n",
    "    Args:\n",
    "        state_variables (tuple[tf.contrib.rnn.LSTMStateTuple]): The LSTM's state variables.\n",
    "        cell (tf.contrib.rnn.MuliRNNCell): An MultiRNNCell consisting of multiple LSTMCells.\n",
    "        max_batch_size (int): The maximum size of batches that are be fed to the LSTMCell.\n",
    "    Returns:\n",
    "        tf.Operation: An operation that sets the LSTM's state to zero.\n",
    "    \"\"\"\n",
    "    zero_states = cell.zero_state(batch_size, tf.float32)\n",
    "    return get_state_update_op(state_variables, zero_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_params(num_inputs, num_layers, num_neurons, num_classes):\n",
    "    \"\"\"Returns the number of trainable parameters of an LSTM.\n",
    "    Args:\n",
    "        num_inputs (int): The input vector size\n",
    "        num_layers (int): The number of layers in the LSTM\n",
    "        num_neurons (int): The number of neurons / units per layer\n",
    "        num_classes (int): The number of classes\n",
    "    Returns:\n",
    "        int: The number of trainable parameters\n",
    "    \"\"\"\n",
    "    num_first_layer = 4 * (num_neurons * (num_inputs + num_neurons) + num_neurons)\n",
    "    num_other_layer = 4 * (num_neurons * 2 * num_neurons + num_neurons)\n",
    "    num_softmax = num_classes * num_neurons + num_classes\n",
    "\n",
    "    return num_first_layer + (num_layers - 1) * num_other_layer + num_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network parameters\n",
    "start_epoch = 1\n",
    "num_epochs = 10\n",
    "num_layers = 2\n",
    "num_neurons = 128\n",
    "learning_rate = 0.0001\n",
    "batch_size = 128\n",
    "output_keep_var = 0.5\n",
    "initial_learning_rate=0.001\n",
    "max_batch_size=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, num_steps, num_inputs], name='input_placeholder')\n",
    "y = tf.placeholder(tf.float32, [None, num_classes], name='labels_placeholder')\n",
    "output_keep_prob = tf.placeholder_with_default(1.0, shape=(), name =\"input_keep_prob\")\n",
    "\n",
    "def build_lstm_cell(num_neurons, output_keep_prob=1.0):\n",
    "    \"\"\"Returns a dropout-wrapped LSTM-cell.\n",
    "    See https://stackoverflow.com/a/44882273/2628369 for why this local function is necessary.\n",
    "    Returns:\n",
    "        tf.contrib.rnn.DropoutWrapper: The dropout-wrapped LSTM cell.\n",
    "     \"\"\"\n",
    "    lstm_cell = tf.contrib.rnn.LSTMCell(num_units=num_neurons, forget_bias=1.0, state_is_tuple=True)\n",
    "    lstm_cell_drop = tf.contrib.rnn.DropoutWrapper(lstm_cell, output_keep_prob=output_keep_prob)\n",
    "    return lstm_cell_drop\n",
    "\n",
    "with tf.name_scope(\"LSTM\"):\n",
    "        with tf.name_scope(\"Cell\"):\n",
    "            multi_layer_cell = tf.contrib.rnn.MultiRNNCell([build_lstm_cell(num_neurons, output_keep_prob=output_keep_prob) for _ in range(num_layers)], state_is_tuple=True)\n",
    "        with tf.variable_scope(\"LSTM_init_state\"):\n",
    "            states = get_state_variables(batch_size, multi_layer_cell)\n",
    "        with tf.name_scope(\"Model\"):\n",
    "            # Unroll the LSTM\n",
    "            outputs, new_states = tf.nn.dynamic_rnn(multi_layer_cell, X, initial_state=states, time_major = False, dtype=tf.float32)#[Batch_size, time_steps, num_neurons]\n",
    "        # Add an operation to update the train states with the last state tensors.\n",
    "        update_op = get_state_update_op(states, new_states)\n",
    "        reset_state_op = get_state_reset_op(states, multi_layer_cell, max_batch_size)\n",
    "        #Softmax_w is 2D, but the outputs are 3D (batch_size, num_timesteps, num_neurons),\n",
    "        outputs = tf.transpose(outputs, [1, 0, 2]) # [num_timesteps, batch_size, num_neurons]\n",
    "        outputs = tf.gather(outputs, int(outputs.get_shape()[0]) - 1) #[num_timesteps, Batch_size, num_neurons]\n",
    "\n",
    "        with tf.variable_scope('softmax'):\n",
    "            softmax_w = tf.get_variable(\"softmax_w\", [num_neurons, num_classes], initializer=tf.truncated_normal_initializer(stddev=0.1))#[num_neurons, num_classes]\n",
    "            softmax_b = tf.get_variable(\"softmax_b\", [num_classes], initializer=tf.constant_initializer(0.1)) #[num_classes,]\n",
    "            logits= tf.matmul(outputs, softmax_w) + softmax_b #[Batch_size, num_classes]\n",
    "        with tf.name_scope('Predictions'):\n",
    "            predictions = tf.nn.softmax(logits, name=\"predictions\")  #[Batch_size, num_classes]\n",
    "        with tf.name_scope('Accuracy'):\n",
    "            correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        with tf.name_scope('Loss'):\n",
    "            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y))\n",
    "        with tf.name_scope('Train'):\n",
    "            optimizer= tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "            trainer=optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    batchNum = mnist.train.num_examples // batch_size\n",
    "    for batch in range(batchNum):\n",
    "        xBatch, yBatch = mnist.train.next_batch(batch_size)\n",
    "        xBatch = xBatch.reshape((batch_size, num_steps, num_inputs))\n",
    "        outputs_train, update_op_train = sess.run([outputs, update_op], feed_dict={X: xBatch, y: yBatch, output_keep_prob:output_keep_var})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
