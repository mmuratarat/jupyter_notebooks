{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's create the moons dataset using Scikit-Learn's make_moons() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from  sklearn.datasets  import make_moons\n",
    "\n",
    "m = 1000\n",
    "X_moons, y_moons = make_moons(m, noise=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_moons[y_moons == 1, 0], X_moons[y_moons == 1, 1], 'go', label=\"Positive\")\n",
    "plt.plot(X_moons[y_moons == 0, 0], X_moons[y_moons == 0, 1], 'r^', label=\"Negative\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must not forget to add an extra bias feature ($x_0 = 1$) to every instance. For this, we just need to add a column full of 1s on the left of the input matrix $\\mathbf{X}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = np.c_[np.ones((m,1)), X_moons]\n",
    "output = y_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[:5,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output is a 1D array but we need to reshape it to a column vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output=output.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's split the data into a training set and a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_ratio):\n",
    "    n = X.shape[0]\n",
    "    test_size = int(n * test_ratio)\n",
    "    X_train = X[:-test_size]\n",
    "    X_test = X[-test_size:]\n",
    "    y_train = y[:-test_size]\n",
    "    y_test = y[-test_size:]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(inputs, output, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_batch(X_train, y_train, batch_size):\n",
    "    rnd_indices = np.random.randint(0, len(X_train), batch_size)\n",
    "    X_batch = X_train[rnd_indices]\n",
    "    y_batch = y_train[rnd_indices]\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch,y_batch = random_batch(X_train, y_train, 5)\n",
    "X_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = X_train.shape[1] -1 \n",
    "X = tf.placeholder(tf.float32, shape=[None, n_inputs+1], name = \"x\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform(shape= [n_inputs + 1, 1], minval = -1.0, maxval=1.0), name = \"theta\")\n",
    "logits = tf.matmul(X, theta, name=\"logits\")\n",
    "#predictions = 1/(1+ tf.exp(-logits))\n",
    "predictions = tf.sigmoid(logits)\n",
    "\n",
    "#the log loss is a good cost function to use for Logistic Regression\n",
    "#$J(\\mathbf{\\theta}) = -\\dfrac{1}{m} \\sum\\limits_{i=1}^{m}{\\left[ y^{(i)} log\\left(\\hat{p}^{(i)}\\right) + (1 - y^{(i)}) log\\left(1 - \\hat{p}^{(i)}\\right)\\right]}$\n",
    "#one can use TensorFlow's tf.losses.log_loss() function\n",
    "\n",
    "loss = tf.losses.log_loss(labels = y, predictions = predictions, weights=1.0, epsilon=1e-07) # uses epsilon = 1e-7 by default\n",
    "#OR one can implement it oneself:\n",
    "#epsilon = 1e-7  # to avoid an overflow when computing the log\n",
    "#loss = -tf.reduce_mean(y * tf.log(y_proba + epsilon) + (1 - y) * tf.log(1 - y_proba + epsilon))\n",
    "learning_rate = 0.01\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "n_epochs = 1000\n",
    "batch_size = 50\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = random_batch(X_train, y_train, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val = loss.eval({X: X_test, y: y_test})\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch:\", epoch, \"\\tLoss:\", loss_val)\n",
    "            \n",
    "    predictions_val = predictions.eval(feed_dict={X: X_test, y: y_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To classify each instance, we can go for maximum likelihood: classify as positive any instance whose estimated probability is greater or equal to 0.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred  = ( predictions_val >= 0.5)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the use case, you may want to choose a different threshold than 0.5: make it higher if you want high precision (but lower recall), and make it lower if you want high recall (but lower precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_idx = y_pred.reshape(-1) # a 1D array rather than a column vector\n",
    "plt.plot(X_test[y_pred_idx, 1], X_test[y_pred_idx, 2], 'go', label=\"Positive\")\n",
    "plt.plot(X_test[~y_pred_idx, 1], X_test[~y_pred_idx, 2], 'r^', label=\"Negative\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "let's create function for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mustafamuratarat/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from  sklearn.datasets  import make_moons\n",
    "\n",
    "num_observations = 1000\n",
    "X, y = make_moons(num_observations, noise=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_enhanced = np.c_[np.ones((num_observations,1)),\n",
    "                   X,\n",
    "                   np.square(X[:, 0]),\n",
    "                   np.square(X[:, 1]),\n",
    "                   X[:, 0] ** 3,\n",
    "                   X[:, 1] ** 3]\n",
    "y=y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_ratio):\n",
    "    n = X.shape[0]\n",
    "    test_size = int(n * test_ratio)\n",
    "    X_train = X[:-test_size]\n",
    "    X_test = X[-test_size:]\n",
    "    y_train = y[:-test_size]\n",
    "    y_test = y[-test_size:]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_enhanced, y, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression(X, y, initializer=None, seed = 42, learning_rate = 0.01):\n",
    "    num_features_including_bias = int(X.get_shape()[1])\n",
    "    with tf.name_scope(\"logistic_regression\"):\n",
    "        with tf.name_scope(\"model\"):\n",
    "            if initializer is None:\n",
    "                initializer = tf.random_uniform(shape= [num_features_including_bias, 1], minval = -1.0, maxval=1.0, seed=seed)\n",
    "            \n",
    "            theta = tf.Variable(initializer, name = \"theta\")\n",
    "            logits = tf.matmul(X, theta, name=\"logits\")\n",
    "            predictions = tf.sigmoid(logits, name=\"predictions\")\n",
    "        with tf.name_scope(\"train\"):\n",
    "            loss = tf.losses.log_loss(labels = y, predictions = predictions, weights=1.0, epsilon=1e-07, scope=\"loss\") # uses epsilon = 1e-7 by default\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "            training_op = optimizer.minimize(loss)\n",
    "            loss_summary = tf.summary.scalar('log_loss', loss)\n",
    "        with tf.name_scope(\"init\"):\n",
    "            init = tf.global_variables_initializer()\n",
    "        with tf.name_scope(\"save\"):\n",
    "            saver = tf.train.Saver()\n",
    "    return predictions, loss, training_op, loss_summary, init, saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_dir(prefix=\"\"):\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "    root_logdir = \"tf_logs\"\n",
    "    if prefix:\n",
    "        prefix += \"-\"\n",
    "    name = prefix + \"run-\" + now\n",
    "    return \"{}/{}/\".format(root_logdir, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = X_train.shape[1]-1\n",
    "logdir = log_dir(\"logreg\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "predictions, loss, training_op, loss_summary, init, saver = logistic_regression(X, y)\n",
    "\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_batch(X_train, y_train, batch_size):\n",
    "    rnd_indices = np.random.randint(0, len(X_train), batch_size)\n",
    "    X_batch = X_train[rnd_indices]\n",
    "    y_batch = y_train[rnd_indices]\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tLoss: 0.629985\n",
      "Epoch: 500 \tLoss: 0.16122364\n",
      "Epoch: 1000 \tLoss: 0.1190321\n",
      "Epoch: 1500 \tLoss: 0.097329214\n",
      "Epoch: 2000 \tLoss: 0.08369793\n",
      "Epoch: 2500 \tLoss: 0.074375816\n",
      "Epoch: 3000 \tLoss: 0.06750215\n",
      "Epoch: 3500 \tLoss: 0.062206898\n",
      "Epoch: 4000 \tLoss: 0.058026794\n",
      "Epoch: 4500 \tLoss: 0.054562975\n",
      "Epoch: 5000 \tLoss: 0.051708292\n",
      "Epoch: 5500 \tLoss: 0.049237743\n",
      "Epoch: 6000 \tLoss: 0.047167286\n",
      "Epoch: 6500 \tLoss: 0.04537664\n",
      "Epoch: 7000 \tLoss: 0.043818746\n",
      "Epoch: 7500 \tLoss: 0.04237422\n",
      "Epoch: 8000 \tLoss: 0.041089162\n",
      "Epoch: 8500 \tLoss: 0.039970912\n",
      "Epoch: 9000 \tLoss: 0.038920246\n",
      "Epoch: 9500 \tLoss: 0.038010743\n",
      "Epoch: 10000 \tLoss: 0.037155695\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10001\n",
    "batch_size = 50\n",
    "n_batches = int(np.ceil(num_observations / batch_size))\n",
    "\n",
    "checkpoint_path = \"/tmp/my_logreg_model.ckpt\"\n",
    "checkpoint_epoch_path = checkpoint_path + \".epoch\"\n",
    "final_model_path = \"./my_logreg_model\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if os.path.isfile(checkpoint_epoch_path):\n",
    "        # if the checkpoint file exists, restore the model and load the epoch number\n",
    "        with open(checkpoint_epoch_path, \"rb\") as f:\n",
    "            start_epoch = int(f.read())\n",
    "        print(\"Training was interrupted. Continuing at epoch\", start_epoch)\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        sess.run(init)\n",
    "\n",
    "    for epoch in range(start_epoch, n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = random_batch(X_train, y_train, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, summary_str = sess.run([loss, loss_summary], feed_dict={X: X_test, y: y_test})\n",
    "        file_writer.add_summary(summary_str, epoch)\n",
    "        if epoch % 500 == 0:\n",
    "            print(\"Epoch:\", epoch, \"\\tLoss:\", loss_val)\n",
    "            saver.save(sess, checkpoint_path)\n",
    "            with open(checkpoint_epoch_path, \"wb\") as f:\n",
    "                f.write(b\"%d\" % (epoch + 1))\n",
    "\n",
    "    saver.save(sess, final_model_path)\n",
    "    predictions = predictions.eval(feed_dict={X: X_test, y: y_test})\n",
    "    os.remove(checkpoint_epoch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9797979797979798\n",
      "0.9797979797979798\n"
     ]
    }
   ],
   "source": [
    "y_test_hat = (predictions >= 0.5)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(precision_score(y_test, y_test_hat))\n",
    "print(recall_score(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b0c6b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_idx = y_test_hat.reshape(-1) # a 1D array rather than a column vector\n",
    "plt.plot(X_test[y_pred_idx, 1], X_test[y_pred_idx, 2], 'go', label=\"Positive\")\n",
    "plt.plot(X_test[~y_pred_idx, 1], X_test[~y_pred_idx, 2], 'r^', label=\"Negative\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mustafamuratarat/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "TensorBoard 1.5.1 at http://Arat-MacBook-Pro.local:6006 (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=tf_logs\n",
    "#http://0.0.0.0:6006/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
