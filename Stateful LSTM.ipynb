{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mustafamuratarat/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2,3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1, #fraction of the memory of the GPU \n",
    "                            allow_growth = True,#If TRUE, use a fraction of between 0 and per process gpu memory fraction. If FALSE, pre-allocate entire GPU memory.\n",
    "                            visible_device_list = \"2,3\") #GPUs 2nd and 3rd used out of 0,1,2,3.\n",
    "config=tf.ConfigProto(gpu_options=gpu_options)\n",
    "\n",
    "print(config.gpu_options.per_process_gpu_memory_fraction)\n",
    "print(config.gpu_options.visible_device_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=pd.read_csv('X_train.txt', header=None).as_matrix()\n",
    "y_train = pd.read_csv('y_train.txt', header=None).as_matrix().ravel()\n",
    "X_test = pd.read_csv('X_test.txt', header=None).as_matrix()\n",
    "y_test = pd.read_csv('y_test.txt', header=None).as_matrix().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y is a array. labelNum is number of distinct values in y, an integer. \n",
    "def convertDummy(y, labelNum):#This is a function one-hot encoding the classes. \n",
    "    labelNum = tf.constant(labelNum) #Construct pre-allocation labelNum.\n",
    "    dummy = tf.one_hot(y, labelNum, axis=1) #Construct operations to create labelNum times columns\n",
    "    sess = tf.Session(config=config) #Defining the session \n",
    "    dummy = sess.run(dummy) #Execute the session\n",
    "    sess.close() #closing the session\n",
    "    return dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Batching datarows\n",
    "#It will return a list of tuples.\n",
    "def miniBatch(x, y, batchSize):\n",
    "    numObs  = x.shape[0]\n",
    "    batches = [] \n",
    "    batchNum = math.floor(numObs / batchSize)\n",
    "\n",
    "    for i in range(batchNum - 1):\n",
    "        xBatch = x[i * batchSize:(i + 1) * batchSize, :]\n",
    "        yBatch = y[i * batchSize:(i + 1) * batchSize, :]\n",
    "        batches.append((xBatch, yBatch))\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Computing the length of sequences. It is needed for variable length sequences\n",
    "def length(sequence):\n",
    "    used = tf.sign(tf.reduce_max(tf.abs(sequence), 2))\n",
    "    length = tf.reduce_sum(used, 1)\n",
    "    length = tf.cast(length, tf.int32)\n",
    "    sess = tf.Session(config=config)\n",
    "    length = sess.run(length)\n",
    "    sess.close()\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_timestep = 60\n",
    "num_classes = 6\n",
    "split_size = max_timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_time(m, split_size):\n",
    "        r = m.shape[0]\n",
    "        extend_row_size = np.math.ceil(r / split_size) * split_size - r\n",
    "        m_p = np.expand_dims(np.pad(m, [(0, extend_row_size), (0, 0)], mode='constant'), axis=0)\n",
    "        result = m_p.reshape((np.math.ceil(r / split_size), split_size, m.shape[1]))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain = split_time(X_train, split_size)\n",
    "ytrain = split_time(convertDummy(y_train-1, num_classes), split_size)\n",
    "Xtest = split_time(X_test, split_size)\n",
    "ytest = split_time(convertDummy(y_test-1, num_classes), split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123, 60, 561)\n",
      "(123, 60, 6)\n",
      "(50, 60, 561)\n",
      "(50, 60, 6)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(Xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_state_variables(batch_size, cell):\n",
    "    # For each layer, get the initial state and make a variable out of it\n",
    "    # to enable updating its value.\n",
    "    state_variables = []\n",
    "    for state_c, state_h in cell.zero_state(batch_size, tf.float32):\n",
    "        state_variables.append(tf.contrib.rnn.LSTMStateTuple(\n",
    "            tf.Variable(state_c, trainable=False),\n",
    "            tf.Variable(state_h, trainable=False)))\n",
    "    # Return as a tuple, so that it can be fed to dynamic_rnn as an initial state\n",
    "    return tuple(state_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_state_update_op(state_variables, new_states):\n",
    "    # Add an operation to update the train states with the last state tensors\n",
    "    update_ops = []\n",
    "    for state_variable, new_state in zip(state_variables, new_states):\n",
    "        # Assign the new state to the state variables on this layer\n",
    "        update_ops.extend([state_variable[0].assign(new_state[0]),\n",
    "                           state_variable[1].assign(new_state[1])])\n",
    "    # Return a tuple in order to combine all update_ops into a single operation.\n",
    "    # The tuple's actual value should not be used.\n",
    "    return tf.tuple(update_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers=3\n",
    "num_neurons = 128\n",
    "num_inputs = Xtrain.shape[2] #561\n",
    "num_classes = ytrain.shape[2] #6\n",
    "num_steps=Xtrain.shape[1] #60\n",
    "\n",
    "#Configuration\n",
    "learning_rate = 0.01\n",
    "batch_size =16\n",
    "num_iterations = 20\n",
    "#During training, you can feed any value you want to the keep_prob placeholder (typically 0.5)\n",
    "train_keep_prob =0.5\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, num_steps, num_inputs], name='input_placeholder')\n",
    "y = tf.placeholder(tf.float32, [None, None, num_classes], name='labels_placeholder')\n",
    "seq_length = tf.placeholder(tf.int32, [None])\n",
    "keep_prob = tf.placeholder_with_default(1.0, shape=())\n",
    "\n",
    "initializer = tf.random_uniform_initializer(-0.1, 0.1, seed=2)\n",
    "#LSTM layers\n",
    "#It can take a while for a recurrent network to learn to remember information from the last time step. \n",
    "#Initialize biases for LSTMâ€™s forget gate to 1 to remember more by default\n",
    "#This is default non-peephole implementation\n",
    "lstm_cells = [tf.contrib.rnn.LSTMCell(num_units=num_neurons, forget_bias=1.0, initializer=initializer, state_is_tuple=True) for layer in range(num_layers)]\n",
    "#Dropout layer before and after each LSTM cells\n",
    "lstm_cells_drop = [tf.contrib.rnn.DropoutWrapper(cell, input_keep_prob=keep_prob) for cell in lstm_cells]\n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(lstm_cells_drop, state_is_tuple=True)\n",
    "\n",
    "#init_states = tf.placeholder(tf.float32, [num_layers, 2, batch_size, num_neurons])\n",
    "init_states = multi_layer_cell.zero_state(tf.shape(X)[0], tf.float32)\n",
    "init_states = tf.identity(init_states, \"init_states\")\n",
    "state_per_layer_list = tf.unstack(init_states, axis=0)\n",
    "rnn_tuple_state = tuple([tf.contrib.rnn.LSTMStateTuple(state_per_layer_list[idx][0], state_per_layer_list[idx][1]) for idx in range(num_layers)])\n",
    "\n",
    "\n",
    "# time_major = False: (batch, time step, input); time_major = True: (time step, batch, input)\n",
    "#The default approach to initializing the state of an RNN is to use a zero state\n",
    "outputs, final_state = tf.nn.dynamic_rnn(multi_layer_cell, X, sequence_length= seq_length, time_major = False, initial_state=init_states, dtype=tf.float32) #[Batch_size, time_steps, num_neurons]\n",
    "\n",
    "output_shape = tf.shape(outputs)#[Batch_size, time_steps, num_neurons]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    #_current_state = np.zeros((num_layers, 2, batch_size, num_neurons))\n",
    "    miniBatches = miniBatch(Xtrain, ytrain, batch_size)\n",
    "    batchNum = len(miniBatches)\n",
    "    for batch in miniBatches:\n",
    "        xBatch = batch[0]\n",
    "        yBatch = batch[1]\n",
    "        seq_length_batch = length(xBatch)\n",
    "        #if you use zero_state you do not need _current_state and assigning a placeholder for it. \n",
    "        outputs_val, final_state_val = sess.run([outputs, final_state], feed_dict={X: xBatch, y: yBatch, seq_length: seq_length_batch, keep_prob:train_keep_prob})\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.01136662,  0.00041855, -0.01009578, ...,  0.00943681,\n",
       "         -0.00986547, -0.00067572],\n",
       "        [ 0.02154926, -0.01915141, -0.02157292, ...,  0.00983158,\n",
       "         -0.0113409 , -0.0146435 ],\n",
       "        [ 0.03555227, -0.02163243, -0.02289967, ...,  0.03586564,\n",
       "         -0.02328831,  0.00632061],\n",
       "        ...,\n",
       "        [-0.25427768, -0.19819836,  0.00894592, ...,  0.1123413 ,\n",
       "         -0.03879779,  0.0866273 ],\n",
       "        [-0.23441458, -0.23270148,  0.03763032, ...,  0.18720868,\n",
       "          0.02642735,  0.16538405],\n",
       "        [-0.18290052, -0.18131953,  0.05075862, ...,  0.14180906,\n",
       "          0.03941987,  0.02738907]],\n",
       "\n",
       "       [[ 0.00106072, -0.00515767,  0.00208643, ...,  0.01168074,\n",
       "         -0.00242058, -0.01811988],\n",
       "        [-0.01250202,  0.00193232, -0.02017763, ...,  0.01489723,\n",
       "         -0.0203504 , -0.02318813],\n",
       "        [-0.01863049, -0.01854887, -0.03328935, ...,  0.019247  ,\n",
       "         -0.04525487, -0.04892085],\n",
       "        ...,\n",
       "        [-0.1576717 , -0.12688969,  0.00923921, ..., -0.04414885,\n",
       "          0.00051227,  0.15262298],\n",
       "        [-0.14293145, -0.06080552,  0.02644861, ...,  0.03360802,\n",
       "         -0.05361088,  0.11998295],\n",
       "        [-0.13270059, -0.10105857,  0.08482726, ...,  0.0514999 ,\n",
       "         -0.04368268,  0.09603653]],\n",
       "\n",
       "       [[ 0.00346616, -0.00161643, -0.00192693, ..., -0.01096704,\n",
       "         -0.00114997,  0.00203115],\n",
       "        [-0.03336346,  0.00849108, -0.00973909, ..., -0.01841907,\n",
       "         -0.00679541, -0.01270067],\n",
       "        [-0.03344575, -0.01350991, -0.02063549, ..., -0.01434916,\n",
       "         -0.02194259, -0.0042858 ],\n",
       "        ...,\n",
       "        [-0.03708003, -0.11804228,  0.07728504, ..., -0.01690833,\n",
       "          0.0772    ,  0.15627591],\n",
       "        [-0.01622565, -0.07226265,  0.05323282, ..., -0.03742915,\n",
       "          0.14432153,  0.13553467],\n",
       "        [ 0.01398618, -0.07366777,  0.05724282, ...,  0.00533094,\n",
       "          0.05907264,  0.13016988]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.01177749, -0.00081702,  0.00472542, ..., -0.02194553,\n",
       "         -0.01982908,  0.01252158],\n",
       "        [-0.00678659,  0.00274694, -0.03752426, ..., -0.00126078,\n",
       "         -0.00844276,  0.02500151],\n",
       "        [-0.02035515,  0.00596784, -0.06633366, ..., -0.03713171,\n",
       "         -0.02239843,  0.04718685],\n",
       "        ...,\n",
       "        [-0.09851579, -0.1601864 , -0.04605517, ...,  0.12482559,\n",
       "          0.18014824,  0.0346727 ],\n",
       "        [-0.07572597, -0.12769938, -0.11548359, ...,  0.1179673 ,\n",
       "          0.18706822,  0.03254569],\n",
       "        [-0.03660783, -0.13188191, -0.07639346, ...,  0.12713341,\n",
       "          0.17072949,  0.04254841]],\n",
       "\n",
       "       [[-0.00597242,  0.00524462, -0.00584456, ..., -0.01092174,\n",
       "         -0.00195211,  0.00600556],\n",
       "        [-0.00136027, -0.00951557,  0.00320865, ..., -0.01012819,\n",
       "         -0.00085932,  0.01434484],\n",
       "        [-0.00720974,  0.00297978,  0.00922934, ..., -0.03625441,\n",
       "          0.00114821,  0.00793097],\n",
       "        ...,\n",
       "        [-0.12950978, -0.20277314, -0.00840003, ..., -0.17449741,\n",
       "         -0.08838504,  0.14427206],\n",
       "        [-0.04426654, -0.18597099,  0.02510089, ..., -0.10829301,\n",
       "         -0.04448066,  0.13911933],\n",
       "        [-0.06926837, -0.15742278,  0.02334676, ..., -0.09176896,\n",
       "         -0.00392158,  0.10130227]],\n",
       "\n",
       "       [[ 0.00975947, -0.02005937, -0.00766766, ..., -0.00221876,\n",
       "          0.00153236,  0.00347599],\n",
       "        [ 0.00081163, -0.00604167,  0.00734504, ..., -0.00462041,\n",
       "         -0.00264691,  0.01767169],\n",
       "        [-0.00362503, -0.03460002, -0.03210625, ...,  0.0214145 ,\n",
       "          0.00456821,  0.0688364 ],\n",
       "        ...,\n",
       "        [-0.1207139 , -0.29242885,  0.0770426 , ..., -0.13811761,\n",
       "          0.19615394,  0.12635423],\n",
       "        [-0.1505828 , -0.23308395,  0.04740486, ..., -0.13702093,\n",
       "          0.160149  ,  0.07889795],\n",
       "        [-0.13540643, -0.25658444,  0.02913087, ..., -0.15791719,\n",
       "          0.13984278,  0.09400382]]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANOTHER EXAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def get_state_variables(batch_size, cell):\n",
    "    # For each layer, get the initial state and make a variable out of it\n",
    "    # to enable updating its value.\n",
    "    state_variables = []\n",
    "    for state_c, state_h in cell.zero_state(batch_size, tf.float32):\n",
    "        state_variables.append(tf.contrib.rnn.LSTMStateTuple(\n",
    "            tf.Variable(state_c, trainable=False),\n",
    "            tf.Variable(state_h, trainable=False)))\n",
    "    # Return as a tuple, so that it can be fed to dynamic_rnn as an initial state\n",
    "    return tuple(state_variables)\n",
    "\n",
    "\n",
    "def get_state_update_op(state_variables, new_states):\n",
    "    # Add an operation to update the train states with the last state tensors\n",
    "    update_ops = []\n",
    "    for state_variable, new_state in zip(state_variables, new_states):\n",
    "        # Assign the new state to the state variables on this layer\n",
    "        update_ops.extend([state_variable[0].assign(new_state[0]),\n",
    "                           state_variable[1].assign(new_state[1])])\n",
    "    # Return a tuple in order to combine all update_ops into a single operation.\n",
    "    # The tuple's actual value should not be used.\n",
    "    return tf.tuple(update_ops)\n",
    "\n",
    "X_batch = np.array([ \n",
    "    [[0,1,2],[9,8,7]],#instance 0\n",
    "    [[3,4,5],[0,0,0]],#instance 1\n",
    "    [[6,7,8],[6,5,4]],#instance 2\n",
    "    [[9,0,1],[3,2,1]]])#instance 3\n",
    "\n",
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "n_layers = 2\n",
    "batch_size = 4\n",
    "\n",
    "X=tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "\n",
    "lstm_cells = [tf.contrib.rnn.LSTMCell(num_units=n_neurons, forget_bias=1.0, state_is_tuple=True) for layer in range(n_layers)]\n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(lstm_cells, state_is_tuple=True)\n",
    "\n",
    "# For each layer, get the initial state. states will be a tuple of LSTMStateTuples.\n",
    "states = get_state_variables(batch_size, multi_layer_cell)\n",
    "\n",
    "# Unroll the LSTM\n",
    "outputs, new_states = tf.nn.dynamic_rnn(multi_layer_cell, X, initial_state=states)\n",
    "\n",
    "# Add an operation to update the train states with the last state tensors.\n",
    "update_op = get_state_update_op(states, new_states)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "outputs_val, new_states_val, update_op_val = sess.run([outputs, new_states, update_op], {X:X_batch})\n",
    "    \n",
    "tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
